{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pprint  \n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import mechanize \n",
    "import time\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "#r = requests.get('http://www.listingallcars.com/results/New')\n",
    "#data = r.text\n",
    "#soup = BeautifulSoup(data)\n",
    "#for link in sou\n",
    "#p.find_all('a')\n",
    "\n",
    "Acura = []\n",
    "AlfaRomeo = []\n",
    "AMGeneral = []\n",
    "AmericanMotors = []\n",
    "AstonMartin = []\n",
    "Audi = []\n",
    "AustinHealey = []\n",
    "Bentley = []\n",
    "BMW = []\n",
    "Buick= []\n",
    "Cadillac = []\n",
    "Chevrolet = []\n",
    "Chrysler = []\n",
    "Daewoo = []\n",
    "Daihatsu = []\n",
    "Datsun = []\n",
    "Delorean = []\n",
    "Dodge = []\n",
    "Eagle = []\n",
    "Ferrari = []\n",
    "Fiat = []\n",
    "Fisker = []\n",
    "Ford = []\n",
    "Freightliner = []\n",
    "Geo = []\n",
    "GMC = []\n",
    "Honda = []\n",
    "Hummer = []\n",
    "Hyundai = []\n",
    "Infiniti = []\n",
    "Isuzu = []\n",
    "Jaguar = []\n",
    "Jeep = []\n",
    "Kia = []\n",
    "Lamborghini = []\n",
    "LandRover = []\n",
    "Lexus = []\n",
    "Lincoln = []\n",
    "Lotus = []\n",
    "Maserati = []\n",
    "Maybach = []\n",
    "Mazda = []\n",
    "Mclaren = []\n",
    "MercedesBenz = []\n",
    "Mercury = []\n",
    "MG = []\n",
    "Mini = []\n",
    "Mitsubishi = []\n",
    "MobilityVentures = []\n",
    "Morgan = []\n",
    "Nissan = []\n",
    "Oldsmobile = []\n",
    "Panoz = []\n",
    "Plymouth = []\n",
    "Pontiac = []\n",
    "Porsche = []\n",
    "Ram = []\n",
    "RollsRoyce = []\n",
    "Saab = []\n",
    "Saturn = []\n",
    "Scion = []\n",
    "Shelby = []\n",
    "Smart = []\n",
    "Subaru = []\n",
    "Suzuki = []\n",
    "Tesla = []\n",
    "Tiffany = []\n",
    "Toyota = []\n",
    "Triumph = []\n",
    "Volkswagen = []\n",
    "Volvo = []\n",
    "VPG = []\n",
    "\n",
    "Car_Make = ['AM+General', 'Acura', 'Alfa+Romeo', 'American+Motors', 'Aston+Martin', 'Audi', 'Austin', 'Austin-Healey', 'BMW', 'Bentley', 'Buick', 'Cadillac', 'Chevrolet', 'Chrysler', 'Daewoo', 'Daihatsu', 'Datsun', 'Delorean', 'Dodge', 'Eagle', 'Ferrari', 'Fiat', 'Fisker', 'Ford', 'Freightliner', 'GMC', 'Geo', 'Honda', 'Hummer', 'Hyundai', 'Infiniti', 'Isuzu', 'Jaguar', 'Jeep', 'Kia', 'Lamborghini', 'Land Rover', 'Lexus', 'Lincoln', 'Lotus', 'MG', 'Maserati', 'Maybach', 'Mazda', 'Mclaren', 'Mercedes-Benz', 'Mercury', 'Mini', 'Mitsubishi', 'Mobility+Ventures', 'Morgan', 'Nissan', 'Oldsmobile', 'Panoz', 'Plymouth', 'Pontiac', 'Porsche', 'Ram', 'Rolls-Royce', 'Saab', 'Saturn', 'Scion', 'Shelby', 'Smart', 'Subaru', 'Suzuki', 'Tesla', 'Tiffany', 'Toyota', 'Triumph', 'VPG', 'Volkswagen', 'Volvo']\n",
    "#Car_Make = ['Acura','Alfa+Romeo','AM+General', 'American+Motors', 'Aston+Martin','Audi',\n",
    "#            'Austin','Austin-Healey','Bentley','BMW','Buick','Cadillac','Chevrolet','Chrysler',\n",
    "#             'Daewoo','Daihatsu','Datsun','Delorean','Dodge','Eagle','Ferrari','Fiat','Fisker','Ford',\n",
    "#             'Freightliner','Geo','GMC','Honda','Hummer','Hyundai','Infiniti','Isuzu','Jaguar','Jeep',\n",
    "#             'Kia','Lamborghini','Land Rover','Lexus','Lincoln','Lotus','Maserati','Maybach','Mazda',\n",
    "#             'Mclaren','Mercedes-Benz','Mercury','MG','Mini','Mitsubishi','Mobility+Ventures','Morgan',\n",
    "#             'Nissan','Oldsmobile','Panoz','Plymouth','Pontiac','Porsche','Ram','Rolls-Royce','Saab',\n",
    "#             'Saturn','Scion','Shelby','Smart','Subaru','Suzuki','Tesla','Tiffany','Toyota','Triumph',\n",
    "#             'Volkswagen','Volvo','VPG']\n",
    "\n",
    "Price_Interval = ['0-5000','5000-10000','10000-15000','15000-20000','20000-25000',\n",
    "                  '25000-30000','30000-35000','35000-40000','40000-45000','45000-50000',\n",
    "                 '50000-max']\n",
    "Colors = ['Black','White','Silver','Gra','Red','Blue','Brown','Green','Beige','Gold','Bronze',\n",
    "         'Orange','Yellow','Purple','Turquoise','Pink']\n",
    "Body = ['convertible','sports','luxury','coupe','suv','pickup','crossover','green','van',\n",
    "       'sedan','hatchback','wagon']\n",
    "\n",
    "# Chevrolet = ['210','3100','Astro''Avalanche+1500','Avalanche+2500','Aveo','Bel+Air',\n",
    "#             'Beretta','Blazer','Camaro','Caprice','Captiva+Sport','Cavalier','Chevelle'\n",
    "#              ,'City Express','Cobalt','Colorado','Corvette','Cruze','Del+Ray',\n",
    "#              'El+Camino','Equinox','Express','Fleetline','G-Series','HHR','HHR+Panel',\n",
    "#             'Impala','Lumina','Luv','Malibu','Malibu+Classic','Malibu+Maxx','Master',\n",
    "#             'Metro','Monte+Carlo','Nomad','Nova','One+Ton','P30','Prizm','S-10','Silverado+1500',\n",
    "#             'Silverado+1500HD','Silverado+2500','Silverado+2500HD','Silverado+3500','Silverado+3500HD',\n",
    "#             'Silverado+Hybrid','Sonic','Spark','Spark+EV','SS','SSR','Suburban','Suburban+10',\n",
    "#             'Suburban+1500','Suburban+20','Suburban+2500','Tahoe','Tracker','TrailBlazer','Traverse','Trax',\n",
    "#             'Uplander','Venture','Volt']\n",
    "\n",
    "\n",
    "\n",
    "#154,176 combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def url_change(car_make = None ,model = None , price_interval = None, body = None,colors = None):\n",
    "    url = 'http://www.everycarlisted.com/search/vehicle_condition-New/year-2017-2017'\n",
    "    if car_make != None:\n",
    "        url = url +'/make-'+car_make\n",
    "    if model != None:\n",
    "        url = url + '/model-'+model\n",
    "    if colors != None:\n",
    "        url = url + '/extcolor-'+colors\n",
    "    if body != None:\n",
    "        url = url + '/body-'+body\n",
    "    if price_interval != None:\n",
    "        url = url + '/price-'+price_interval\n",
    "    url = url + '/sort-1/page-'\n",
    "    return url\n",
    "\n",
    "####Browser mechanize functionality\n",
    "br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "# cartype = 'Rolls-Royce'\n",
    "# url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\n",
    "# br.open(url+str(1))\n",
    "# response = br.response()\n",
    "# soup = BeautifulSoup(response,\"html.parser\")\n",
    "\n",
    "def Open_Browser(url, page):\n",
    "    br.open(url+str(page))\n",
    "    response = br.response()\n",
    "    soup = BeautifulSoup(response,\"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def web2var(string):\n",
    "    string = string.replace('+','')\n",
    "    string = string.replace('-','')\n",
    "    return string\n",
    "\n",
    "def var2web(string):\n",
    "    if ' ' in string:\n",
    "        string = string.replace(' ','+')\n",
    "    return string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Scrape car model names prior to scraping price and car name\n",
    "modelDictionary = defaultdict(list)\n",
    "for i in range(0,len(Car_Make)):\n",
    "    value = []\n",
    "    url = url_change(Car_Make[i])\n",
    "#     print url\n",
    "    soup = Open_Browser(url,1)\n",
    "    soup = soup.find('select',{\"id\":\"SearchForm_carModel\"})\n",
    "    for text in soup.stripped_strings:\n",
    "#         print text\n",
    "#        key = Car_Make[i]\n",
    "        key = web2var(Car_Make[i])\n",
    "        modelDictionary[key].append(text)\n",
    "#     print modelDictionary[key]\n",
    "\n",
    "\n",
    "for l in modelDictionary.values():\n",
    "    if 'All Models' in l: l.remove('All Models')\n",
    "\n",
    "        \n",
    "key_list = []\n",
    "for key in sorted(modelDictionary.iterkeys()):\n",
    "    key_list.append(\"%s\" % (key))\n",
    "# print key_list\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Remove All Models\n",
    "# key_list = []\n",
    "# for l in modelDictionary.values():\n",
    "#     if 'All Models' in l: l.remove('All Models')\n",
    "\n",
    "        \n",
    "\n",
    "# for key in sorted(modelDictionary.iterkeys()):\n",
    "#     key_list.append(\"%s\" % (key))\n",
    "# print key_list\n",
    "\n",
    "#value_list = []\n",
    "#for key, value in modelDictionary.iteritems() :\n",
    "#    key_list.append(key)\n",
    "#    value_list.append(value)\n",
    "\n",
    "#print key_list\n",
    "\n",
    "#print key_list[22]    \n",
    "# \n",
    "#a = value_list[22][5]\n",
    "\n",
    "#test = var2web(a) \n",
    "\n",
    "# modelDictionary[key_list[0]]\n",
    "# Car_Make[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in range(0,len(value_list)-1):\n",
    "#     for j in range(0,len(value_list[i])-1):\n",
    "#             value_list[i][j] = var2web(value_list[i][j])\n",
    "\n",
    "# print 'Done'\n",
    "\n",
    "# # value_list[0][17]\n",
    "# # print key_list[0]\n",
    "# # print modelDictionary['Mercury']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output = []\n",
    "# for i in range(0,len(Car_Make)):\n",
    "#     for j in range(0,len(Price_Interval)):\n",
    "#             for k in range(0,len(Colors)):\n",
    "#                 for l in range(0,len(Body)):\n",
    "#                         url = url_change(Car_Make[i], Price_Interval[j], Colors[k], Body[l]\n",
    "#                         output.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "price = []\n",
    "carname = []\n",
    "# print key_list[11]\n",
    "# print Car_Make[11]\n",
    "# print modelDictionary[key_list[11]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "####Browser mechanize functionality\n",
    "br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "# cartype = 'Rolls-Royce'\n",
    "# url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\n",
    "# br.open(url+str(1))\n",
    "# response = br.response()\n",
    "# soup = BeautifulSoup(response,\"html.parser\")\n",
    "\n",
    "def Open_Browser(url, page):\n",
    "    br.open(url+str(page))\n",
    "    response = br.response()\n",
    "    soup = BeautifulSoup(response,\"html.parser\")\n",
    "    return soup\n",
    "\n",
    "#@Deprecated\n",
    "# def Total_Trucks(soup, cartype, body=None): \n",
    "#     total_cars = str(soup.body.h1.text)\n",
    "#     print total_cars\n",
    "#     if body == 'suv' or body =='pickup':\n",
    "#         total_cars = total_cars[0:len(total_cars)-32-len(cartype)].replace(',','')\n",
    "#     else:\n",
    "#         total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#     print total_cars\n",
    "#     total_cars= int(total_cars)\n",
    "#     return total_cars\n",
    "\n",
    "def Total_Cars(soup, cartype):\n",
    "    total_cars = str(soup.body.h1.text)\n",
    "    print total_cars\n",
    "    total_cars = total_cars.replace(',','')\n",
    "    total_cars = int(re.search(r'\\d+', total_cars).group())\n",
    "#   total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#    print total_cars\n",
    "    total_cars= int(total_cars)\n",
    "    return total_cars\n",
    "    \n",
    "#46010 is total\n",
    "#i = 1\n",
    "#haven't done Chevrolet because they have a lot (175k)\n",
    "# i = 68\n",
    "#for i in range(12,len(Car_Make)):\n",
    "\n",
    "for i in range(569,len(Car_Make)):\n",
    "    url = url_change(Car_Make[i])\n",
    "    soup = Open_Browser(url, i)\n",
    "    total_cars = Total_Cars(soup, Car_Make[i])\n",
    "    print url;\n",
    "    #     print total_cars\n",
    "    if total_cars > 3000:\n",
    "        #model iteration\n",
    "        for h in range(19 , len(modelDictionary[key_list[i]])):\n",
    "            url = url_change(Car_Make[i], modelDictionary[key_list[i]][h])\n",
    "            soup = Open_Browser(url, i)\n",
    "            total_cars = Total_Cars(soup, Car_Make[i])\n",
    "    #            print url\n",
    "    #            print total_cars\n",
    "            if total_cars > 3000:\n",
    "                for k in range(0 , len(Price_Interval)):\n",
    "                    url = url_change(Car_Make[i], modelDictionary[key_list[i]][h], Price_Interval[k])\n",
    "                    soup = Open_Browser(url, i)\n",
    "                    total_cars = Total_Cars(soup, Car_Make[i])\n",
    "    #                    print url\n",
    "    #                    print total_cars\n",
    "                    if total_cars > 3000:\n",
    "                        for l in range(0 , len(Body)):\n",
    "                            url = url_change(Car_Make[i], modelDictionary[key_list[i]][h], Price_Interval[k],Body[l])\n",
    "                            soup = Open_Browser(url, i)\n",
    "                            total_cars = Total_Cars(soup, Car_Make[i])\n",
    "    #                            print url\n",
    "    #                            print total_cars\n",
    "                            if total_cars > 3000:\n",
    "                                for j in range(0,len(Colors)):\n",
    "                                    url = url_change(Car_Make[i], modelDictionary[key_list[i]][h], Price_Interval[k],Body[l],Colors[j])\n",
    "                                    soup = Open_Browser(url, i)\n",
    "                                    total_cars = Total_Cars(soup, Car_Make[i])\n",
    "    #                                    print url\n",
    "    #                                    print total_cars\n",
    "                            else:\n",
    "                                for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "                                    soup = Open_Browser(url,page)\n",
    "                                    for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                                        carname.append(row.text)    \n",
    "                                    for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                                        price.append(row.text[8:])\n",
    "    #                                    print page\n",
    "                    else:\n",
    "                        for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "                            soup = Open_Browser(url,page)\n",
    "                            for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                                carname.append(row.text)    \n",
    "                            for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                                price.append(row.text[8:])\n",
    "    #                            print page  \n",
    "            else:\n",
    "                for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "                    soup = Open_Browser(url,page)\n",
    "                    for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                        carname.append(row.text)    \n",
    "                    for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                        price.append(row.text[8:])\n",
    "    #                    print page\n",
    "    else:\n",
    "        for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "            soup = Open_Browser(url,page)\n",
    "            for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                carname.append(row.text)    \n",
    "            for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                price.append(row.text[8:])\n",
    "    #            print page\n",
    "\n",
    "\n",
    "print 'Done'\n",
    "                            \n",
    "#     count = count +1\n",
    "#     url_change = url + str(i)\n",
    "#     br.open(url_change)\n",
    "#     response = br.response()\n",
    "#     soup = BeautifulSoup(response,\"html.parser\")\n",
    "#     for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "#         carname.append(row.text)    \n",
    "#     for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "#         price.append(row.text[8:])\n",
    "#############################Write Dataframe to .csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ####Browser mechanize functionality\n",
    "# br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "\n",
    "\n",
    "# #Used to count and figure out which ones are over 3000 even after Body type\n",
    "# def Open_Browser(url, page):\n",
    "#     br.open(url+str(page))\n",
    "#     response = br.response()\n",
    "#     soup = BeautifulSoup(response,\"html.parser\")\n",
    "#     return soup\n",
    "\n",
    "# def Total_Trucks(soup, cartype, body=None):\n",
    "#     total_cars = str(soup.body.h1.text)\n",
    "#     print total_cars\n",
    "#     if body == 'suv' or body =='pickup':\n",
    "#         total_cars = total_cars[0:len(total_cars)-32-len(cartype)].replace(',','')\n",
    "#     else:\n",
    "#         total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#     print total_cars\n",
    "#     total_cars= int(total_cars)\n",
    "#     return total_cars\n",
    "\n",
    "# def Total_Cars(soup, cartype):\n",
    "#     total_cars = str(soup.body.h1.text)\n",
    "#     print total_cars\n",
    "#     total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#     print total_cars\n",
    "#     total_cars= int(total_cars)\n",
    "#     return total_cars\n",
    "    \n",
    "# #46010 is total\n",
    "# for i in range(1,len(Car_Make)):\n",
    "#     url = url_change(Car_Make[i])\n",
    "#     soup = Open_Browser(url, i)\n",
    "#     total_cars = Total_Cars(soup, Car_Make[i])\n",
    "#     print url;\n",
    "#     print total_cars\n",
    "#     if total_cars > 3000:\n",
    "#         print total_cars > 3000\n",
    "#         for j in range(1,len(Price_Interval)):\n",
    "#             url = url_change(Car_Make[i], Price_Interval[j])\n",
    "#             soup = Open_Browser(url, i)\n",
    "#             total_cars = Total_Cars(soup, Car_Make[i])\n",
    "#             print url\n",
    "#             print total_cars\n",
    "# #     else:\n",
    "#             if total_cars > 3000:\n",
    "#                 for k in range(1 , len(Colors)):\n",
    "#                     url = url_change(Car_Make[i], Price_Interval[j], Colors[k])\n",
    "#                     soup = Open_Browser(url, i)\n",
    "#                     total_cars = Total_Cars(soup, Car_Make[i])\n",
    "#                     print url\n",
    "#                     print total_cars\n",
    "# #             else:\n",
    "#                     if total_cars > 3000:\n",
    "#                         for l in range(1 , len(Body)):\n",
    "#                             url = url_change(Car_Make[i], Price_Interval[j], Colors[k],Body[l])\n",
    "#                             soup = Open_Browser(url, i)\n",
    "#                             total_cars = Total_Trucks(soup, Car_Make[i], Body[l])\n",
    "#                             print url\n",
    "#                             print total_cars\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "# cartype = 'Rolls-Royce'\n",
    "# url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-Chevrolet/year-2017-2017/sort-1/page-'\n",
    "# #url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\n",
    "# br.open(url+str(1))\n",
    "# response = br.response()\n",
    "# soup = BeautifulSoup(response,\"html.parser\")\n",
    "# #print soup.prettify()\n",
    "\n",
    "\n",
    "# price = []\n",
    "# carname = []\n",
    "# count = 0\n",
    "\n",
    "# total_cars = str(soup.body.h1.text)\n",
    "# total_cars = int(total_cars[0:len(total_cars)-30-len(cartype)].replace(',',''))\n",
    "# # print soup.find_all('select',{\"class\":\"col-md-12 form-control\"})\n",
    "# for row in soup.find_all('select',{\"id\":\"SearchForm_carModel\"}):\n",
    "#     print row.text\n",
    "# #if total_cars\n",
    "\n",
    "# # soup = BeautifulSoup(response,\"html.parser\")\n",
    "# # for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "# #     carname.append(row.text)    \n",
    "# # for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "# #     price.append(row.text[8:])\n",
    "    \n",
    "# #print price\n",
    "# #print total_cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#############################Write Dataframe to .csv\n",
    "output = pd.DataFrame(price,carname)\n",
    "#print(output)\n",
    "output.to_csv('C:\\Users\\gordon.tsai\\Google Drive\\WEG\\CarPriceDistribution.csv', sep = ',', encoding = 'utf-8' )\n",
    "\n",
    "print len(price)\n",
    "#print(\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
